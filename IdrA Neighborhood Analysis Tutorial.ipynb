{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative genomics of DIR\n",
    "\n",
    "How conserved are the proteins near iodate reductase (IriA?) across the phylogeny of IriA and IriA/AioA-like proteins?\n",
    "\n",
    "\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "The following must be installed and in your path:\n",
    "- ncbi-genome-download: https://github.com/kblin/ncbi-genome-download\n",
    "- cd-hit\n",
    "- FastTree\n",
    "- muscle\n",
    "\n",
    "#### Methods\n",
    "\n",
    "1. Download genomes\n",
    "  - Download genomes from a list of RefSeq/GenBank accessions\n",
    "2. Define phylogeny\n",
    "  - Identify HMM hit in each genome\n",
    "  - Generate phylogenetic tree of HMM hits\n",
    "  - Define groups within the tree (\"clades\")\n",
    "3. Define gene neighborhood composition\n",
    "  - Obtain genes within +/- 10 positions of HMM hits (\"gene neigborhoods\")\n",
    "  - Group proteins from gene neighborhoods by sequence similarity (\"subfamilies\")\n",
    "\n",
    "#### Analysis\n",
    "\n",
    "- Which subfamilies are conserved which clades?\n",
    "- What the functions of those subfamilies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "os.chdir('/path/to/your/directory')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['svg.fonttype'] = 'none' # Editable SVG text\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download assemblies from list of RefSeq/GenBank accessions\n",
    "\n",
    "RefSeq accessions start with \"GCF_\", while GenBank accessions start with \"GCA_\". If both accessions are available for a given genome, use the RefSeq accession.\n",
    "\n",
    "\n",
    "Only a subset of available files are downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = False \n",
    "path_to_genomes = './data/genomes/'\n",
    "if download == True:\n",
    "\n",
    "    # Download\n",
    "    for db in ['refseq', 'genbank']:\n",
    "        accessions_to_download = path_to_genomes + db + '-accessions.txt'\n",
    "        print(accessions_to_download)\n",
    "        !ncbi-genome-download -s $db -F 'protein-fasta,features,assembly-report' \\\n",
    "        -A $accessions_to_download -m ./data/genomes/metadata.csv -o ./data/genomes all\n",
    "    \n",
    "    # Unzip any gzipped files\n",
    "    path_to_downloads = path_to_genomes + '/*/*/*/*gz'\n",
    "    print(path_to_downloads)\n",
    "    !gunzip $path_to_downloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define phylogeny\n",
    "\n",
    "### Identify HMM hit in each genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input files\n",
    "\n",
    "hmm = './data/hmm/combined_iriA_aioA.hmm'\n",
    "threshold = 640\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "import os\n",
    "\n",
    "# Search every genome and record sequence and ID of hits\n",
    "\n",
    "path_to_hmm = './data/hmm/'\n",
    "tab = path_to_hmm + 'iriA-hits.out'\n",
    "txt = path_to_hmm + 'iriA-hits.txt'\n",
    "hits = path_to_hmm + 'iriA-hits.faa'\n",
    "\n",
    "if 'iriA-hits.faa' in os.listdir(path_to_hmm):\n",
    "    os.remove(hits)\n",
    "\n",
    "hmmhits = {} # genomeid : geneid #longer list\n",
    "path_to_hits = {} # accession : path #shorter list\n",
    "\n",
    "\n",
    "# For each genome in each database\n",
    "for db in ['refseq/', 'genbank/']:\n",
    "    for domain in os.listdir(path_to_genomes + db): # 'bacteria/', 'archaea/'\n",
    "        for accession in os.listdir(path_to_genomes + db + domain):\n",
    "            # Search all protein-fasta files\n",
    "            directory = path_to_genomes + db + domain + '/' + accession + '/'\n",
    "            #path_to_hits[accession] = directory\n",
    "            for protein_fasta in [directory + x for x in os.listdir(directory) if '.faa' in x]:\n",
    "                \n",
    "                # Hmmsearch\n",
    "                hmmsearch = ' '.join(['hmmsearch', '--noali', '--tblout', tab, '-T', str(threshold), hmm, protein_fasta])\n",
    "                sp.call(hmmsearch, shell=True)\n",
    "                #print(hmmsearch)\n",
    "\n",
    "                # Record hits\n",
    "                hit_geneids = []\n",
    "                with open(tab, 'r') as fh:\n",
    "                    for line in fh.readlines():\n",
    "                        if '#' not in line:\n",
    "                            geneid = line.strip().split(' ')[0]\n",
    "                            hit_geneids.append(geneid)\n",
    "\n",
    "                # Record \n",
    "                hmmhits[accession] = []\n",
    "\n",
    "                for geneid in hit_geneids:\n",
    "\n",
    "                    # Append hits to .faa file\n",
    "                    with open(txt, 'w') as fh:\n",
    "                        fh.write(geneid)\n",
    "\n",
    "                    hits_to_faa = ' '.join([\"perl -ne 'if(/^>(\\S+)/){$c=$i{$1}}$c?print:chomp;$i{$_}=1 if @ARGV'\", txt, protein_fasta, \">>\", hits])\n",
    "                    sp.call(hits_to_faa, shell=True)\n",
    "\n",
    "                    # Record path for future use\n",
    "                    path_to_hits[accession] = directory\n",
    "                    \n",
    "\n",
    "                # Record Genome ID for each Gene ID\n",
    "                hmmhits[accession].append(geneid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Harmonizes dictionaries so that no false directories are called later\n",
    "for k in list(hmmhits.keys()):\n",
    "    if k not in path_to_hits:\n",
    "        del hmmhits[k]\n",
    "with open('iodate_reducing_genomes.txt', 'w') as fh:\n",
    "    for item in hmmhits: \n",
    "        fh.write(item + '\\n')\n",
    "print(len(hmmhits))\n",
    "print(len(path_to_hits))\n",
    "print('Both printed numbers should be equal, if they are not, the code will break!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate phylogenetic tree of HMM hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faa_ingroup = hits\n",
    "faa_outgroup = './data/tree/aioA_bigtree.faa' # Outgroup to idrA proteins\n",
    "temp = './data/tree/temp.faa'\n",
    "faa = './data/tree/iriA-all.faa' \n",
    "#If redrawing the tree--don't forget to erase both the temp and all files, otherwise you get duplicates\n",
    "\n",
    "# Add outgroup\n",
    "concat = ' '.join(['cat', faa_outgroup, faa_ingroup, '>>', faa])\n",
    "sp.call(concat, shell=True)\n",
    "\n",
    "# Format headers to be compatible with ete3 package\n",
    "format_headers = ' '.join([\"sed 's|(||g'\", faa, \"| sed 's|)||g' | sed 's|:|-|g' | sed 's|\\*||' >\", temp])\n",
    "sp.call(format_headers, shell=True)\n",
    "\n",
    "# Remove empty entries and duplicate entries from FASTA\n",
    "drop_empties_and_duplicates =' '.join(['sh scripts/clean_fasta_entries.sh', temp, faa])\n",
    "sp.call(drop_empties_and_duplicates, shell=True)\n",
    "\n",
    "# Align\n",
    "aln = './data/tree/iriA.aln'\n",
    "align = ' '.join(['muscle', '-in', faa, '-out', aln])\n",
    "sp.call(align, shell=True)\n",
    "\n",
    "# Trim the alignment to, say, where >80% of positions aren't gaps\n",
    "filt = 80\n",
    "f_aln = './data/tree/iriA-'+ str(filt) + '.aln'\n",
    "filter_gaps = ' '.join(['python3', './scripts/remove-gapped-positions.py', '-p', str(filt), '-i', aln, '-o', f_aln])\n",
    "sp.call(filter_gaps, shell=True)\n",
    "\n",
    "# Tree\n",
    "tree = './data/tree/iriA.nwk' \n",
    "fasttree = ' '.join(['fasttree','-boot 10000', aln, \">\", tree])\n",
    "sp.call(fasttree, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creates a dictionary with accession and names so the tree can be fully annotated later###\n",
    "names_list = []\n",
    "accession_list = []\n",
    "with open('./data/tree/iriA-all.faa', 'r') as fh:\n",
    "    for line in fh.readlines():\n",
    "        if '>' in line:\n",
    "            line = line.split('[')[1]\n",
    "            line = line.split(']')[0]\n",
    "            names_list.append(line)\n",
    "with open('./data/tree/iriA-all.faa', 'r') as fh:    \n",
    "    for accession in fh.readlines():\n",
    "        if '>' in accession:\n",
    "            accession = accession.split('>')[1]\n",
    "            accession = accession.split(' ')[0]\n",
    "            accession_list.append(accession)\n",
    "     \n",
    "    \n",
    "##This is for the pruned tree...remove if needed\n",
    "asc_names = dict(zip(accession_list, names_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot phylogenetic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Circular rooted tree\n",
    "from ete3 import Tree, NodeStyle, TreeStyle, TextFace, PhyloTree\n",
    "\n",
    "t = Tree(tree, format=0)\n",
    "#t = PhyloTree(tree, format=0)\n",
    "\n",
    "def style_tree(t, branch_support_text=False, branch_support_dots=True, dots_on_leaves=False):\n",
    "\n",
    "    # Tree style\n",
    "    ts = TreeStyle()\n",
    "    ts.show_leaf_name = True\n",
    "    ts.show_branch_support = branch_support_text\n",
    "    \n",
    "    \n",
    "    # Node styles\n",
    "    \n",
    "    simple = NodeStyle()\n",
    "    simple[\"shape\"] = \"circle\"\n",
    "    simple[\"size\"] = 0\n",
    "    simple[\"fgcolor\"] = \"black\"\n",
    "    \n",
    "    h_support = NodeStyle()\n",
    "    h_support[\"shape\"] = \"circle\"\n",
    "    h_support[\"size\"] = 14\n",
    "    h_support[\"fgcolor\"] = 'black'\n",
    "    \n",
    "    m_support = NodeStyle()\n",
    "    m_support[\"shape\"] = \"circle\"\n",
    "    m_support[\"size\"] = 14\n",
    "    m_support[\"fgcolor\"] = '#939598' #  grey\n",
    "    \n",
    "    l_support = NodeStyle()\n",
    "    l_support[\"shape\"] = \"circle\"\n",
    "    l_support[\"size\"] = 14\n",
    "    l_support[\"fgcolor\"] = '#E6E7E8' # light grey    \n",
    "\n",
    "    if branch_support_dots == True:\n",
    "        \n",
    "        # Circles colored by support values\n",
    "        for node in t.traverse():\n",
    "            \n",
    "            support_val = node.support\n",
    "            \n",
    "            if support_val >= 0.99:\n",
    "                node.set_style(h_support)\n",
    "                \n",
    "            elif support_val >= 0.90:\n",
    "                node.set_style(m_support)\n",
    "                \n",
    "            elif support_val >= 0.80:\n",
    "                node.set_style(l_support)\n",
    "                \n",
    "            else:\n",
    "                node.set_style(simple)\n",
    "                \n",
    "            if dots_on_leaves == False:\n",
    "                if node.is_leaf() == True:\n",
    "                    node.set_style(simple)\n",
    "    else:\n",
    "        \n",
    "        # No circles indicating support\n",
    "        for node in t.traverse():\n",
    "            node.set_style(simple)\n",
    "        \n",
    "    return ts\n",
    "\n",
    "# Set outgroup from FAA\n",
    "# http://etetoolkit.org/docs/latest/tutorial/tutorial_trees.html#tree-rooting\n",
    "with open(faa_outgroup) as fh:\n",
    "    # ID of outgroups used for tree construction\n",
    "    outgroup = [line.strip().split(' ')[0].split('>')[1] for line in fh.readlines() if \">\" in line]\n",
    "ancestor = t.get_common_ancestor(outgroup[0],outgroup[2])\n",
    "t.set_outgroup(ancestor)\n",
    "\n",
    "### Get three or so outgroups from the aioA tree. HMM should be more inclusive outgroup further out ###\n",
    "\n",
    "\n",
    "# Ladderize (sort tree)\n",
    "t.ladderize()\n",
    "\n",
    "#Check if in dictionary\n",
    "def checkKey(dict, key): \n",
    "    if key in dict.keys():\n",
    "        return dict[key]\n",
    "\n",
    "# Record order of node leaves\n",
    "order = []\n",
    "for node in t.traverse('postorder'):\n",
    "    if len(node.name) > 5: # Remove non-name nodes\n",
    "        ID = node.name.strip()\n",
    "        ID_new = checkKey(asc_names, ID) # 'KPDAEFOI_00687'\n",
    "        order.append(ID)\n",
    "        node.name = ID_new #ID + ' ' + ID_new\n",
    "dict_order = dict(zip(order,range(len(order))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Style and plot\n",
    "ts = style_tree(t, branch_support_text=False, branch_support_dots=True)\n",
    "ts.show_leaf_name  = False\n",
    "ts.mode = \"c\"\n",
    "ts.arc_start = 0 # 0 degrees = 3 o'clock\n",
    "ts.arc_span = 360\n",
    "\n",
    "\n",
    "label_size = 20\n",
    "for node in t.traverse():\n",
    "    if node.is_leaf():\n",
    "\n",
    "        # Show leaf labels\n",
    "        name_face = TextFace(node.name, fgcolor=\"black\", fsize=label_size, tight_text=True, ftype='Arial')\n",
    "        node.add_face(name_face, column=0, position='branch-right')\n",
    "\n",
    "#Shading\n",
    "nst1 = NodeStyle()\n",
    "nst1[\"bgcolor\"] = \"lightgreen\"\n",
    "n1 = t.get_common_ancestor(\"Halobiforma lacisalsi\", \"Halorubrum kocurii\")\n",
    "n1.set_style(nst1)\n",
    "\n",
    "nst2 = NodeStyle()\n",
    "nst2[\"bgcolor\"] = \"orchid\"\n",
    "n2 = t.get_common_ancestor(\"Dehalococcoidia bacterium\", \"Vibrio\")\n",
    "n2.set_style(nst2)\n",
    "\n",
    "nst3 = NodeStyle()\n",
    "nst3[\"bgcolor\"] = 'silver'\n",
    "n3 = t.get_common_ancestor(\"Microvirga guangxiensis\", \"Pyrobaculum ferrireducens\")\n",
    "n3.set_style(nst3)\n",
    "\n",
    "ts.scale =  250\n",
    "#ts.title.add_face(TextFace(\"Phylogeny of Iodate Reductases and Arsenite Oxidases\", fsize=20))\n",
    "t.set_outgroup('Pseudomonas aeruginosa PAO1 NasC')\n",
    "t.show(tree_style=ts)\n",
    "something = t.render('aioA_tree_publication.png', dpi=300, tree_style=ts)\n",
    "\"%%inline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define groups within tree based on phylogenetic distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cache_distances(tree):\n",
    "    \n",
    "    # Precalculate distances of all nodes to the root \n",
    "    # Reference: https://www.biostars.org/p/97409/\n",
    "    node2rootdist = {tree:0}\n",
    "    for node in tree.iter_descendants('preorder'):\n",
    "        node2rootdist[node] = node.dist + node2rootdist[node.up]\n",
    "    return node2rootdist\n",
    "\n",
    "def collapse(tree, min_dist):\n",
    "    \n",
    "\n",
    "    \n",
    "    # Collapse nodes by a minimum distance and remove children of collapsed nodes\n",
    "    # Reference: https://www.biostars.org/p/97409/\n",
    "    \n",
    "    dict_collapsing = {} # old node : collapsed node\n",
    "    \n",
    "    # cache the tip content of each node to reduce the number of times the tree is traversed\n",
    "    node2tips = tree.get_cached_content()\n",
    "    root_distance = cache_distances(tree)\n",
    "\n",
    "    # Traverse tree and iteratively collapse nodes\n",
    "    N = -1\n",
    "    for node in tree.get_descendants('preorder'):\n",
    "        if not node.is_leaf():\n",
    "            avg_distance_to_tips = np.mean([root_distance[tip]-root_distance[node]\n",
    "                                         for tip in node2tips[node]])\n",
    "\n",
    "            if avg_distance_to_tips < min_dist:\n",
    "                # do whatever, ete support node annotation, deletion, labeling, etc.\n",
    "\n",
    "                # rename\n",
    "                N += 1\n",
    "                collapsed_node_name = (\"n\" + str(N) + '_' + str(len(node2tips[node])))\n",
    "                \n",
    "                node.name = collapsed_node_name\n",
    "                # Previous text:\n",
    "                #+' COLLAPSED avg_d:%g {%s}' %(avg_distance_to_tips, ','.join([tip.name for tip in node2tips[node]]))\n",
    "                \n",
    "                #dict_collapsing[node.name] = [tip.name for tip in node2tips[node]]\n",
    "                # Store collapsed nodes\n",
    "                for tip in node2tips[node]:\n",
    "                    if tip.is_leaf():\n",
    "                        if tip.name in dict_collapsing.keys():\n",
    "                            pass\n",
    "                        else:\n",
    "                            dict_collapsing[tip.name] = collapsed_node_name\n",
    "                \n",
    "                # label\n",
    "                node.add_features(collapsed=True)\n",
    "\n",
    "                # set drawing attribute so they look collapsed when displayed with tree.show()\n",
    "                node.img_style['draw_descendants'] = False\n",
    "                \n",
    "            #if node in outgroup nodes:\n",
    "                #Rename, store, label, etc.\n",
    "        \n",
    "    # Remove collapsed nodes (labeled) from tree\n",
    "    for node in tree.search_nodes(collapsed=True):\n",
    "        for ch in node.get_children():\n",
    "            ch.detach()\n",
    "    \n",
    "    # Add non-collapsed nodes to dict\n",
    "    for node in order:\n",
    "        if node not in dict_collapsing.keys():\n",
    "            dict_collapsing[node] = node\n",
    "\n",
    "    \n",
    "    return tree, dict_collapsing\n",
    "          \n",
    "    \n",
    "tcoll = t.copy()                \n",
    "tcoll, tree_node_groups = collapse(tcoll, 0.4) # Adjust value to desired group size\n",
    "tcoll.ladderize() # Order by increasing node partition\n",
    "tcoll = Tree(tcoll.write())\n",
    "\n",
    "ts = style_tree(tcoll, branch_support_text=False, branch_support_dots=True)\n",
    "tcoll.render(\"%%inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define neighborhood composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain genes within +/- 10 positions of HMM hits (\"gene neigborhoods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "proximity = 10\n",
    "\n",
    "def filter_by_relative_proximity(df):\n",
    "\n",
    "    # Calculate proximity to reference gene for other genes on dffold\n",
    "    df['Start Coord'] = df['Start Coord'].astype(int)\n",
    "    df['End Coord'] = df['End Coord'].astype(int)\n",
    "    startcoord_ref = int(df.at[hit,'Start Coord'])\n",
    "    endcoord_ref = int(df.at[hit,'End Coord'])\n",
    "\n",
    "    # Define baseline values for hit\n",
    "    df.at[hit,'Rel Start Coord'] = 0\n",
    "    df.at[hit,'Rel Strand'] = '+'\n",
    "\n",
    "    # Depending on strand (top=+, bottom=-)\n",
    "    sign = df.at[hit,'Strand']\n",
    "\n",
    "    if sign == \"+\": # Subtract all coords from initial start coord\n",
    "        vector = +1.0\n",
    "        strand_key = {\"+\" : \"+\", \"-\" : \"-\"}\n",
    "        df['Rel Start Coord'] = df['Start Coord'] - startcoord_ref\n",
    "        df['Rel End Coord'] = (df['End Coord'] - startcoord_ref)\n",
    "        df['Rel Strand'] = df['Strand'].map(strand_key)\n",
    "\n",
    "    elif sign == \"-\": # -1 * Subtract all coords from initial end coord (true start)\n",
    "        vector = -1.0\n",
    "        strand_key = {\"-\" : \"+\", \"+\" : \"-\"} # Flip strands\n",
    "        df['Rel Start Coord'] = vector*(df['End Coord'] - endcoord_ref)\n",
    "        df['Rel End Coord'] = vector*(df['Start Coord'] - endcoord_ref)\n",
    "        df['Rel Strand'] = df['Strand'].map(strand_key)\n",
    "\n",
    "    # Assign Rel # below or above gene\n",
    "    df = df.sort_values(by='Rel Start Coord')\n",
    "    df.loc[(df['Rel Start Coord'] > 0), 'Rel #'] = range(1, 1 + len(df['Rel Start Coord'][(df['Rel Start Coord'] > 0)].tolist()), 1)\n",
    "    df.loc[(df['Rel Start Coord'] < 0), 'Rel #'] = list(reversed(range(-1, -1 - len(df['Rel Start Coord'][(df['Rel Start Coord'] < 0)].tolist()), -1)))\n",
    "    df.at[hit,'Rel #'] = 0\n",
    "\n",
    "    # Filter by proximity\n",
    "    df = df[(df['Rel #'] <= proximity) & (df['Rel #'] >= -1*proximity)]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "for n, genome in enumerate(list(sorted(hmmhits.keys()))):       \n",
    "    \n",
    "    for FILE in os.listdir(path_to_hits[genome]):\n",
    "        if \"_feature_table.txt\" in FILE and genome in FILE and \"lock\" not in FILE:\n",
    "            feature_table = FILE\n",
    "        if \"_assembly_report.txt\" in FILE and genome in FILE  and \"lock\" not in FILE:\n",
    "            assembly_report = FILE\n",
    "        if \"protein.faa\" in FILE and genome in FILE  and \"lock\" not in FILE:\n",
    "            proteins = FILE\n",
    "\n",
    "\n",
    "    # Extract data from genome*assembly_report\n",
    "    strain = ''\n",
    "    genbank = ''\n",
    "    refseq = ''\n",
    "    genome_length = 0\n",
    "    metagenomic = False\n",
    "\n",
    "    with open(path_to_hits[genome] + assembly_report, 'r+', encoding=\"utf-8\") as fh:\n",
    "\n",
    "        for line in fh.readlines():\n",
    "\n",
    "            if '#' in line:\n",
    "                # Name\n",
    "                key = '# Organism name:  '\n",
    "                if key in line:\n",
    "                    line = line.strip().split(key)[1]\n",
    "                    if r' (' in line:\n",
    "                        line = line.split(r' (')[0]\n",
    "                    genome_name = line\n",
    "\n",
    "                # Strain\n",
    "                elif '# Infraspecific name:  strain=' in line:\n",
    "                    strain = line.strip().split('# Infraspecific name:  strain=')[1]\n",
    "                elif '# Isolate:  ' in line:\n",
    "                    strain = line.strip().split('# Isolate:  ')[1]\n",
    "                elif '# Assembly name:  ' in line:\n",
    "                    strain = line.strip().split('# Assembly name:  ')[1]\n",
    "\n",
    "                # Genbank\n",
    "                elif '# GenBank assembly accession: ' in line:\n",
    "                    genbank = line.strip().split('# GenBank assembly accession: ')[1]\n",
    "\n",
    "                # Refseq\n",
    "                elif '# RefSeq assembly accession: ' in line:\n",
    "                    refseq = line.strip().split('# RefSeq assembly accession: ')[1]\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            # Sequence length\n",
    "            else:\n",
    "                val = line.strip().split('\\t')[8]\n",
    "                if val == 'na':\n",
    "                    val = 0\n",
    "                contig_length = int(val)\n",
    "                genome_length += contig_length\n",
    "\n",
    "    # Extract genome information from genome*_feature_table.txt\n",
    "    gen = pd.read_csv(path_to_hits[genome] + feature_table, sep='\\t')\n",
    "    gen = gen[(gen['# feature'] == 'CDS') & (gen['class'] != 'without_protein')]\n",
    "    rename_columns = {'genomic_accession':'Scaffold ID',\n",
    "                        'start': 'Start Coord',\n",
    "                        'end' : 'End Coord',\n",
    "                        'strand' : 'Strand',\n",
    "                        'product_accession' : 'Gene ID',\n",
    "                        'locus_tag' : 'Locus Tag',\n",
    "                        'name' : 'Gene Product Name'}\n",
    "    gen = gen.rename(columns=rename_columns)\n",
    "    gen = gen.loc[:,rename_columns.values()]\n",
    "\n",
    "    num_cds = len(gen.index)\n",
    "    gen['Genome ID'] = [genome] * num_cds\n",
    "    gen['Genome Name'] = [genome_name] * num_cds\n",
    "    gen['Strain'] = [strain] * num_cds\n",
    "    gen['Genbank Accession'] = [genbank] * num_cds\n",
    "    gen['Refseq Accession'] = [refseq] * num_cds\n",
    "    gen['Gene Count'] = [num_cds] * num_cds\n",
    "    gen['Genome Length (bp)'] = [genome_length] * num_cds\n",
    "\n",
    "    gen = gen.set_index('Gene ID')\n",
    "    gen['Gene ID'] = gen.index.tolist()\n",
    "\n",
    "    # From genome data, keep data from genes with +/- N genes to gene on same contig/scaffold\n",
    "    for hit in hmmhits[genome]:\n",
    "\n",
    "        # Create dataframe of only genes on same scaffold as hit\n",
    "        scaffold = gen.at[hit,'Scaffold ID']\n",
    "\n",
    "        # If list, choose first instance\n",
    "        if type(scaffold) == type(np.array([])):\n",
    "            scaffold = scaffold[0]\n",
    "\n",
    "        scaf = gen[gen['Scaffold ID'] == scaffold].copy()\n",
    "        scaf = scaf.drop_duplicates(subset='Gene ID')\n",
    "\n",
    "        # Filter by relative proximity\n",
    "        scaf = filter_by_relative_proximity(scaf)\n",
    "\n",
    "        # Append to dataframe\n",
    "        if n == 0:\n",
    "            df = scaf.copy()\n",
    "        else:\n",
    "            df = pd.concat([df,scaf])\n",
    "\n",
    "\n",
    "# Both a GenBank and RefSeq accession are found in the Genome IDs, remove the Genbank accession\n",
    "accessions = set(df['Genome ID'].tolist())\n",
    "genbank = df[~df['Refseq Accession'].isnull()].drop_duplicates('Genome ID')['Genbank Accession'].tolist()\n",
    "refseq = df[~df['Refseq Accession'].isnull()].drop_duplicates('Genome ID')['Refseq Accession'].tolist()\n",
    "paired_accessions = list(zip(genbank, refseq))\n",
    "\n",
    "redundant_accessions = []\n",
    "for pair in paired_accessions:\n",
    "    gen, ref = pair\n",
    "    if ref in accessions and gen in accessions:\n",
    "        redundant_accessions.append(gen)\n",
    "        \n",
    "df = df.drop(df[df['Genome ID'].isin(redundant_accessions)].index)\n",
    "        \n",
    "# Extract protein sequences from gene neighborhoods to new file\n",
    "id_file = 'temp.txt'\n",
    "hit_file = \"./data/subfamilies/neighborhoods.faa\"\n",
    "if \"neighborhoods.faa\" in os.listdir(\"./data/subfamilies/\"):\n",
    "    os.remove(hit_file)\n",
    "\n",
    "for genome in list(sorted(hmmhits.keys())):\n",
    "\n",
    "\n",
    "    genes = df[df['Genome ID'] == genome]['Gene ID'].tolist()\n",
    "    genes = [str(x) for x in genes]\n",
    "    #print(genes)\n",
    "    #if 'GBD43204.1' in genes:\n",
    "    #    print('yes')\n",
    "\n",
    "    for FILE in os.listdir(path_to_hits[genome]):  #Go and manually remove the .gz files!\n",
    "        if \"protein.faa\" in FILE and genome in FILE:\n",
    "            proteins = FILE\n",
    "\n",
    "    with open(id_file,'w') as fh: #makes list of genes\n",
    "        fh.write('\\n'.join(genes))\n",
    "        #print('\\n'.join(genes))\n",
    "\n",
    "    command = ' '.join([\"perl -ne 'if(/^>(\\S+)/){$c=$i{$1}}$c?print:chomp;$i{$_}=1 if @ARGV'\", #gets sequences from list of genes\n",
    "                        id_file, path_to_hits[genome] + proteins, \">>\", hit_file])\n",
    "\n",
    "\n",
    "    sp.call(command,shell=True, env=os.environ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save hits onto a searchable spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/path/to/your/directory/hit_neighborhoods.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group proteins from gene neighborhoods by sequence similarity (\"subfamilies\")\n",
    "\n",
    "Subfamilies numbered by abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set variables\n",
    "seqs =\"./data/subfamilies/neighborhoods.faa\"\n",
    "mmseq_output = './data/subfamilies/mmseq' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a readable tab separated file with protein subfamilies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./data/subfamilies/neighborhoods_clean.faa_proteinClustering')\n",
    "\n",
    "with open('orf2subfamily.tsv') as f:\n",
    "    with open(\"orf2subfamily_clean.tsv\",'w') as f1:\n",
    "        next(f) # skip header line\n",
    "        for line in f:\n",
    "            f1.write(line)\n",
    "            \n",
    "geneid_to_subfamily = {}\n",
    "with open('orf2subfamily_clean.tsv') as fh:\n",
    "    reader = csv.reader(fh, delimiter='\\t')\n",
    "    for line in reader:\n",
    "        subfamily = line[1]\n",
    "        subfamily = subfamily.split(sep='m')\n",
    "        subfamily = subfamily[1]\n",
    "        geneid = line[0]\n",
    "        geneid_to_subfamily[geneid] = subfamily\n",
    "        \n",
    "os.chdir('path/to/your/directory')\n",
    "            \n",
    "df['mmseq'] = df['Gene ID'].map(geneid_to_subfamily)\n",
    "cdhit_sorted = df.groupby('mmseq').count().sort_values('Scaffold ID', ascending=False).index.tolist()\n",
    "df['Subfamily'] = df['mmseq'].map(dict(zip(cdhit_sorted, range(len(cdhit_sorted))))).astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "### What are the functions of these subfamilies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subfam_prod = df.groupby('Subfamily')['Gene Product Name'].agg(lambda x: pd.Series.mode(x)[0])\n",
    "subfamily_to_product = dict(zip(subfam_prod.index.tolist(),subfam_prod.tolist()))\n",
    "\n",
    "df['Gene Count'] = [1] * len(df.index)\n",
    "df['Tree Node Group'] = df['Gene ID'].map(tree_node_groups)\n",
    "\n",
    "df['Tree Node Group'] = df['Scaffold ID'].map(dict(zip(df[~df['Tree Node Group'].isnull()]['Scaffold ID'].tolist(),\n",
    "                                                       df[~df['Tree Node Group'].isnull()]['Tree Node Group'].tolist())))\n",
    "\n",
    "subfams = pd.DataFrame(df.groupby(['Subfamily']).count()['Gene Count'])\n",
    "\n",
    "subfams['Mode Gene Product Name'] = subfams.index.map(subfamily_to_product)\n",
    "subfams = subfams.sort_values(by='Gene Count', ascending=False)\n",
    "\n",
    "subfams = subfams[subfams.index != 'nan']\n",
    "os.chdir('./data/')\n",
    "subfams.to_excel('subfamily_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which subfamilies are conserved in each clade?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "plt.rcParams['svg.fonttype'] = 'none' # Editable SVG text\n",
    "\n",
    "def add_polygon(coordinates):\n",
    "    \n",
    "    # Plots a gene as an arrow with offsets from the end of translation\n",
    "    # Reference: https://nickcharlton.net/posts/drawing-animating-shapes-matplotlib.html\n",
    "\n",
    "    x1,x2,y,h,color,strand = coordinates\n",
    "    \n",
    "    edge_color='black'\n",
    "    edge_width=1\n",
    "    alpha=0.75\n",
    "    \n",
    "    # Polygon for ORF\n",
    "    points = [[x1, y-h/2],   # left bottom\n",
    "              [x1, y],       # left center\n",
    "              [x1, y + h/2], # left top\n",
    "              [x2, y + h/2], # right top\n",
    "              [x2, y],       # right center\n",
    "              [x2, y - h/2]] # right bottom\n",
    "    \n",
    "    # Short genes require different offset length\n",
    "    x_offset = h/3\n",
    "    if x_offset > abs(x1-x2):\n",
    "        x_offset = abs(x1-x2)\n",
    "    \n",
    "    # \"Point\" the polygon to indicate direction\n",
    "    if strand == '+':\n",
    "        # Arrow on right\n",
    "        points[3][0] = x2 - x_offset \n",
    "        points[5][0] = x2 - x_offset \n",
    "    else:\n",
    "        # Arrow on left\n",
    "        points[0][0] = x1 + x_offset \n",
    "        points[2][0] = x1 + x_offset \n",
    "    \n",
    "    # Plot parameters\n",
    "    polygon = plt.Polygon(points, fc=color, edgecolor=edge_color, linewidth=edge_width, alpha=alpha)\n",
    "    \n",
    "    return plt.gca().add_patch(polygon)\n",
    "\n",
    "def set_relative_coordinates(df, central_gene):\n",
    "    \n",
    "    # Calculate proximity to reference gene for other genes on scaffold\n",
    "    df['Start Coord'] = df['Start Coord'].astype(int)\n",
    "    df['End Coord'] = df['End Coord'].astype(int)\n",
    "    startcoord_ref = int(df.at[central_gene,'Start Coord'])\n",
    "    endcoord_ref = int(df.at[central_gene,'End Coord'])\n",
    "    \n",
    "    # Define baseline values for hit\n",
    "    df.at[central_gene,'Rel Start Coord'] = 0\n",
    "    df.at[central_gene,'Rel Strand'] = '+'\n",
    "\n",
    "    # Depending on strand (top=+, bottom=-)\n",
    "    sign = df.at[central_gene,'Strand']\n",
    "\n",
    "    if sign == \"+\": # Subtract all coords from initial start coord\n",
    "        vector = +1.0\n",
    "        strand_key = {\"+\" : \"+\", \"-\" : \"-\"}\n",
    "        df['Rel Start Coord'] = df['Start Coord'] - startcoord_ref\n",
    "        df['Rel End Coord'] = (df['End Coord'] - startcoord_ref)\n",
    "        df['Rel Strand'] = df['Strand'].map(strand_key)\n",
    "\n",
    "    elif sign == \"-\": # -1 * Subtract all coords from initial end coord (true start)\n",
    "        vector = -1.0\n",
    "        strand_key = {\"-\" : \"+\", \"+\" : \"-\"} # Flip strands\n",
    "        df['Rel Start Coord'] = vector*(df['End Coord'] - endcoord_ref)\n",
    "        df['Rel End Coord'] = vector*(df['Start Coord'] - endcoord_ref)\n",
    "        df['Rel Strand'] = df['Strand'].map(strand_key)\n",
    "\n",
    "    # Assign Rel # below or above gene\n",
    "    df = df.sort_values(by='Rel Start Coord')\n",
    "    df.loc[(df['Rel Start Coord'] > 0), 'Rel #'] = range(1, 1 + len(df['Rel Start Coord'][(df['Rel Start Coord'] > 0)].tolist()), 1)\n",
    "    df.loc[(df['Rel Start Coord'] < 0), 'Rel #'] = list(reversed(range(-1, -1 - len(df['Rel Start Coord'][(df['Rel Start Coord'] < 0)].tolist()), -1)))\n",
    "    df.at[central_gene,'Rel #'] = 0\n",
    "    \n",
    "    # Filter by proximity\n",
    "    proximity = 10\n",
    "    df = df[(df['Rel Start Coord'] <= proximity) & (df['Rel End Coord'] >= -1*proximity)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_gene_clusters(df, ordered_scaffolds, label_subfams=False, saveas='svg'):\n",
    "\n",
    "    # Spacing of plot\n",
    "    y = 0 # initial y-coordinate\n",
    "    h = 700 # height of genes\n",
    "    spacing_vertical = 3.25 # aspect ratio between scaffolds\n",
    "\n",
    "    # Plot genes in Cluster N (0 is likely key genes) arranged by coordinates\n",
    "    plt.figure(figsize=(20,len(ordered_scaffolds)))\n",
    "    \n",
    "    for scaffold in ordered_scaffolds:\n",
    "\n",
    "        y = y - h * spacing_vertical # assign new y-coordinate\n",
    "                \n",
    "        # Set relative coordinates for subset\n",
    "        scaf = df[df['Scaffold ID'] == scaffold].copy()\n",
    "        scaf = scaf.drop_duplicates('Gene ID')\n",
    "\n",
    "        # Plot genome text\n",
    "        genome = str(scaf['Genome Name'][0][0:40])\n",
    "        plt.text(15000, y, genome, size=20, verticalalignment='center')\n",
    "        \n",
    "        # Plot ea. gene in scaffold\n",
    "        genes_in_scaffold = scaf.index.tolist()\n",
    "        for GENE in genes_in_scaffold:\n",
    "\n",
    "            # Gene\n",
    "            x1 = scaf.at[GENE,'Rel Start Coord'] / 2\n",
    "            x2 = scaf.at[GENE,'Rel End Coord'] / 2\n",
    "            strand = scaf.at[GENE,'Rel Strand']\n",
    "            color = scaf.at[GENE, 'Color']\n",
    "            coordinates = [x1, x2, y, h, color, strand]\n",
    "\n",
    "            if label_subfams == True:\n",
    "                # Label\n",
    "                label_x = x1 + 0.1 * abs(x1 - x2)\n",
    "                label_y = y + h * spacing_vertical / 2\n",
    "                if scaf.at[GENE,'Subfamily'] != 'nan':\n",
    "                    label_text = scaf.at[GENE,'Subfamily']\n",
    "                #if scaf.at[GENE,'Subfamily'] < 4:\n",
    "                #    label_text = scaf.at[GENE,'Subfamily']\n",
    "                else:\n",
    "                    label_text = ' '\n",
    "                plt.text(label_x, label_y, label_text, size=12, rotation=45, verticalalignment='center')\n",
    "            add_polygon(coordinates)\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.axis('off')\n",
    "    mat = np.linspace(0, 1, 256)\n",
    "    mat = np.vstack((mat, mat))\n",
    "    plt.imshow(mat, aspect='auto', cmap='Purples')\n",
    "    plt.colorbar(orientation='horizontal', pad = -0.03).ax.tick_params(labelsize=22)\n",
    "    plt.text(s='Gene Frequency in Selected Genomes', x=0, y=-1)\n",
    "    \n",
    "        \n",
    "    return plt.show()\n",
    "\n",
    "# Color subfamilies by presence in genomes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "total_genomes = len(set(df['Genome ID'].tolist()))\n",
    "cmap = cm.get_cmap('Purples', total_genomes)\n",
    "norm = pd.DataFrame(subfams['Gene Count'] / subfams['Gene Count'].max())\n",
    "\n",
    "norm.columns = ['Count']\n",
    "norm['Color'] = norm['Count'].apply(lambda x : cmap(x))\n",
    "subfam_to_color = dict(zip(norm.index.tolist(), norm['Color'].tolist()))\n",
    "subfam_to_color['nan'] = 'white'\n",
    "\n",
    "df['Tree Order'] = df['Gene ID'].map(dict_order)\n",
    "\n",
    "\n",
    "\n",
    "#### Assign color for nan\n",
    "df['Color'] = df['Subfamily'].map(subfam_to_color)\n",
    "os.chdir('./data/subfamilies')\n",
    "plot_gene_clusters(df=df, \n",
    "                   ordered_scaffolds=df.sort_values(by='Tree Order').loc[:,'Scaffold ID'].drop_duplicates().tolist(),\n",
    "                   label_subfams=True, saveas='svg')\n",
    "\n",
    "#plt.savefig(\"subfamily_clusters\", format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
